"""Core agent for PR review using OpenHands SDK."""

import logging
import subprocess
from pathlib import Path
from typing import Any, Literal
from urllib.parse import urlparse

from . import _tty as _terminal_safety  # noqa: F401

from dotenv import load_dotenv
from openhands.sdk import Conversation
from openhands.sdk.conversation import get_agent_final_response
from openhands.sdk.event import Event
from openhands.sdk.workspace import LocalWorkspace
from openhands.tools.delegate.visualizer import DelegationVisualizer
from openhands.tools.delegate.impl import DelegateExecutor

from .github import GitHubAPIError, fetch_github_pr_info, normalize_github_metadata
from .gitlab import GitLabAPIError, fetch_gitlab_mr_info, post_gitlab_mr_comment
from .llm import create_hodor_agent
from .prompts.pr_review_prompt import build_pr_review_prompt
from .skills import discover_skills
from .workspace import cleanup_workspace, setup_workspace


def aggregate_all_costs(conversation: Conversation) -> dict[str, Any]:
    """Aggregate costs from orchestrator and all worker agents.

    Returns:
        Dict with total_cost, orchestrator_cost, worker_costs breakdown
    """
    result = {
        "orchestrator_cost": 0.0,
        "orchestrator_tokens": 0,
        "worker_costs": {},
        "total_worker_cost": 0.0,
        "total_worker_tokens": 0,
        "total_cost": 0.0,
        "total_tokens": 0,
    }

    # Get orchestrator metrics
    if hasattr(conversation, "conversation_stats"):
        try:
            combined = conversation.conversation_stats.get_combined_metrics()
            if combined:
                result["orchestrator_cost"] = combined.accumulated_cost or 0
                if combined.accumulated_token_usage:
                    usage = combined.accumulated_token_usage
                    result["orchestrator_tokens"] = (
                        (usage.prompt_tokens or 0) +
                        (usage.completion_tokens or 0)
                    )
        except Exception:
            pass

    # Try to get worker metrics from delegate executor
    try:
        # Access the agent's tools to find the delegate executor
        if hasattr(conversation, "agent") and hasattr(conversation.agent, "_tools"):
            for tool_name, tool_def in conversation.agent._tools.items():
                if tool_name == "delegate" and hasattr(tool_def, "executor"):
                    executor = tool_def.executor
                    if isinstance(executor, DelegateExecutor):
                        # Found the delegate executor, iterate sub-agents
                        for agent_id, sub_conv in executor._sub_agents.items():
                            if hasattr(sub_conv, "conversation_stats"):
                                try:
                                    sub_metrics = sub_conv.conversation_stats.get_combined_metrics()
                                    if sub_metrics:
                                        cost = sub_metrics.accumulated_cost or 0
                                        tokens = 0
                                        if sub_metrics.accumulated_token_usage:
                                            u = sub_metrics.accumulated_token_usage
                                            tokens = (u.prompt_tokens or 0) + (u.completion_tokens or 0)

                                        result["worker_costs"][agent_id] = {
                                            "cost": cost,
                                            "tokens": tokens,
                                        }
                                        result["total_worker_cost"] += cost
                                        result["total_worker_tokens"] += tokens
                                except Exception:
                                    pass
                        break
    except Exception as e:
        logger.debug(f"Could not aggregate worker costs: {e}")

    result["total_cost"] = result["orchestrator_cost"] + result["total_worker_cost"]
    result["total_tokens"] = result["orchestrator_tokens"] + result["total_worker_tokens"]

    return result

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

Platform = Literal["github", "gitlab"]


def detect_platform(pr_url: str) -> Platform:
    """Detect the platform (GitHub or GitLab) from the PR URL."""
    parsed = urlparse(pr_url)
    hostname = parsed.hostname or ""

    # Check for GitLab-specific patterns first (works for both gitlab.com and self-hosted)
    if "/-/merge_requests/" in pr_url or "gitlab" in hostname:
        return "gitlab"
    # Check for GitHub-specific patterns
    elif "/pull/" in pr_url or "github" in hostname:
        return "github"
    else:
        logger.debug(f"Unknown platform for URL {pr_url}, defaulting to GitHub")
        return "github"


def parse_pr_url(pr_url: str) -> tuple[str, str, int, str]:
    """
    Parse PR/MR URL to extract owner, repo, PR/MR number, and host.

    Examples:
        GitHub: https://github.com/owner/repo/pull/123 -> ('owner', 'repo', 123, 'github.com')
        GitLab: https://gitlab.com/owner/repo/-/merge_requests/123 -> ('owner', 'repo', 123, 'gitlab.com')
        Self-hosted: https://gitlab.example.com/group/repo/-/merge_requests/118 -> ('group', 'repo', 118, 'gitlab.example.com')
    """
    parsed = urlparse(pr_url)
    path_parts = [p for p in parsed.path.split("/") if p]
    host = parsed.netloc

    # GitHub format: /owner/repo/pull/123
    if len(path_parts) >= 4 and path_parts[2] == "pull":
        owner = path_parts[0]
        repo = path_parts[1]
        pr_number = int(path_parts[3])
        return owner, repo, pr_number, host

    # GitLab format: /group/subgroup/repo/-/merge_requests/123
    elif "merge_requests" in path_parts:
        mr_index = path_parts.index("merge_requests")
        if mr_index < 2 or mr_index + 1 >= len(path_parts):
            raise ValueError(f"Invalid GitLab MR URL format: {pr_url}. Expected .../-/merge_requests/<number>")
        if path_parts[mr_index - 1] != "-":
            raise ValueError(f"Invalid GitLab MR URL format: {pr_url}. Missing '/-/' segment before merge_requests.")

        repo = path_parts[mr_index - 2]
        owner_parts = path_parts[: mr_index - 2]
        owner = "/".join(owner_parts) if owner_parts else path_parts[0]
        pr_number = int(path_parts[mr_index + 1])
        return owner, repo, pr_number, host

    else:
        raise ValueError(
            f"Invalid PR/MR URL format: {pr_url}. Expected GitHub pull request or GitLab merge request URL."
        )


def post_review_comment(
    pr_url: str,
    review_text: str,
    model: str | None = None,
) -> dict[str, Any]:
    """
    Post a review comment on a GitHub PR or GitLab MR using CLI tools.

    Args:
        pr_url: URL of the pull request or merge request
        review_text: The review text to post as a comment
        model: LLM model used for the review (optional, for transparency)

    Returns:
        Dictionary with comment posting result
    """
    platform = detect_platform(pr_url)
    logger.info(f"Posting comment to {platform} PR/MR: {pr_url}")

    try:
        owner, repo, pr_number, host = parse_pr_url(pr_url)
    except ValueError as e:
        return {"success": False, "error": str(e)}

    # Append model information to review text for transparency
    if model:
        review_text_with_footer = f"{review_text}\n\n---\n\n*Review generated by Hodor using `{model}`*"
    else:
        review_text_with_footer = review_text

    try:
        if platform == "github":
            # Use gh CLI to post comment
            subprocess.run(
                [
                    "gh",
                    "pr",
                    "review",
                    str(pr_number),
                    "--repo",
                    f"{owner}/{repo}",
                    "--comment",
                    "--body",
                    review_text_with_footer,
                ],
                check=True,
                capture_output=True,
                text=True,
            )
            logger.info(f"Successfully posted review to GitHub PR #{pr_number}")
            return {"success": True, "platform": "github", "pr_number": pr_number}

        elif platform == "gitlab":
            # Use glab CLI to post comment
            post_gitlab_mr_comment(
                owner,
                repo,
                pr_number,
                review_text_with_footer,
                host=host,
            )
            logger.info(f"Successfully posted review to GitLab MR !{pr_number} on {owner}/{repo}")
            return {"success": True, "platform": "gitlab", "mr_number": pr_number}

        else:
            return {"success": False, "error": f"Unsupported platform: {platform}"}

    except GitLabAPIError as e:
        logger.error(f"Failed to post GitLab comment: {e}")
        return {"success": False, "error": str(e)}
    except subprocess.CalledProcessError as e:
        logger.error(f"Failed to post GitHub comment: {e}")
        logger.error(f"Command output: {e.stderr if hasattr(e, 'stderr') else 'N/A'}")
        return {"success": False, "error": str(e)}
    except Exception as e:
        logger.error(f"Error posting comment: {str(e)}")
        return {"success": False, "error": str(e)}


def review_pr(
    pr_url: str,
    model: str = "anthropic/claude-sonnet-4-5-20250929",
    temperature: float | None = None,
    reasoning_effort: str | None = None,
    custom_prompt: str | None = None,
    prompt_file: Path | None = None,
    user_llm_params: dict[str, Any] | None = None,
    verbose: bool = False,
    cleanup: bool = True,
    workspace_dir: Path | None = None,
    output_format: str = "markdown",
    max_iterations: int = 500,
    lite_model: str | None = None,
    enable_subagents: bool = True,
) -> str:
    """
    Review a pull request using OpenHands agent with bash tools.

    Args:
        pr_url: URL of the pull request or merge request
        model: LLM model name (default: Claude Sonnet 4.5)
        temperature: Sampling temperature (if None, auto-selected)
        reasoning_effort: For reasoning models: "low", "medium", or "high"
        custom_prompt: Optional custom prompt text (inline)
        prompt_file: Optional path to custom prompt file
        user_llm_params: Additional LLM parameters
        verbose: Enable verbose logging
        cleanup: Clean up workspace after review (default: True)
        workspace_dir: Directory to use for workspace (if None, creates temp dir). Reuses if same repo.
        output_format: Output format - "markdown" or "json" (default: "markdown")
        max_iterations: Maximum number of agent iterations (default: 500, use -1 for unlimited)
        lite_model: Lite model for worker subagents (e.g., "anthropic/claude-3-5-haiku-20241022")
        enable_subagents: Enable worker subagent delegation (default: True)

    Returns:
        Review text as string (format depends on output_format)

    Raises:
        ValueError: If URL is invalid
        RuntimeError: If review fails
    """
    logger.info(f"Starting PR review for: {pr_url}")

    # Parse PR URL
    try:
        owner, repo, pr_number, host = parse_pr_url(pr_url)
        platform = detect_platform(pr_url)
    except ValueError as e:
        logger.error(f"Invalid PR URL: {e}")
        raise

    logger.info(f"Platform: {platform}, Repo: {owner}/{repo}, PR: {pr_number}, Host: {host}")

    # Setup workspace (clone repo and checkout PR branch)
    workspace = None
    target_branch = "main"  # Default fallback
    diff_base_sha = None  # GitLab CI provides this for deterministic diffs
    try:
        workspace, target_branch, diff_base_sha = setup_workspace(
            platform=platform,
            owner=owner,
            repo=repo,
            pr_number=str(pr_number),
            host=host,
            working_dir=workspace_dir,
            reuse=workspace_dir is not None,  # Only reuse if user specified a workspace dir
        )
        logger.info(
            f"Workspace ready: {workspace} (target branch: {target_branch}, "
            f"diff_base_sha: {diff_base_sha[:8] if diff_base_sha else 'N/A'})"
        )
    except Exception as e:
        logger.error(f"Failed to setup workspace: {e}")
        raise RuntimeError(f"Failed to setup workspace: {e}") from e

    # Discover repository skills (from .cursorrules, agents.md, .hodor/skills/)
    skills = []
    try:
        skills = discover_skills(workspace)
        if skills:
            logger.info(f"Discovered {len(skills)} repository skill(s)")
        else:
            logger.debug("No repository skills found")
    except Exception as e:
        logger.warning(f"Failed to discover skills (continuing without skills): {e}")

    # Create OpenHands agent with repository skills
    try:
        agent = create_hodor_agent(
            model=model,
            temperature=temperature,
            reasoning_effort=reasoning_effort,
            verbose=verbose,
            llm_overrides=user_llm_params,
            skills=skills,
            lite_model=lite_model,
            enable_subagents=enable_subagents,
        )
    except Exception as e:
        logger.error(f"Failed to create OpenHands agent: {e}")
        if workspace and cleanup:
            cleanup_workspace(workspace)
        raise RuntimeError(f"Failed to create agent: {e}") from e

    mr_metadata = None
    if platform == "gitlab":
        try:
            mr_metadata = fetch_gitlab_mr_info(owner, repo, pr_number, host, include_comments=True)
        except GitLabAPIError as e:
            logger.warning(f"Failed to fetch GitLab metadata: {e}")
    elif platform == "github":
        try:
            github_raw = fetch_github_pr_info(owner, repo, pr_number)
            mr_metadata = normalize_github_metadata(github_raw)
        except GitHubAPIError as e:
            logger.warning(f"Failed to fetch GitHub metadata: {e}")

    # Build prompt
    try:
        prompt = build_pr_review_prompt(
            pr_url=pr_url,
            owner=owner,
            repo=repo,
            pr_number=str(pr_number),
            platform=platform,
            target_branch=target_branch,
            diff_base_sha=diff_base_sha,
            mr_metadata=mr_metadata,
            custom_instructions=custom_prompt,
            custom_prompt_file=prompt_file,
            output_format=output_format,
            enable_subagents=enable_subagents,
        )
    except Exception as e:
        logger.error(f"Failed to build prompt: {e}")
        if workspace and cleanup:
            cleanup_workspace(workspace)
        raise RuntimeError(f"Failed to build prompt: {e}") from e

    #  Event callback for monitoring agent progress
    def on_event(event: Any) -> None:
        """Callback for streaming agent events in verbose mode."""
        if not verbose:
            return

        event_type = type(event).__name__

        # Log LLM API calls (for detailed token/cost tracking)
        if isinstance(event, Event):
            # This captures raw LLM messages for detailed analysis
            # Useful for debugging prompt engineering or cost optimization
            logger.debug(f"ü§ñ LLM Event: {event_type}")

        # Log agent actions
        if hasattr(event, "action") and event.action:
            action_type = type(event.action).__name__
            if action_type == "ExecuteBashAction":
                logger.info(f"üîß Executing: {event.action.command[:100]}")
            elif action_type == "FileEditAction":
                logger.info(f"‚úèÔ∏è  Editing file: {getattr(event.action, 'file_path', 'unknown')}")
            elif action_type == "MessageAction":
                logger.info("üí¨ Agent thinking...")

        # Log observations (results)
        if hasattr(event, "observation") and event.observation:
            obs_type = type(event.observation).__name__
            if obs_type == "ExecuteBashObservation" and hasattr(event.observation, "exit_code"):
                exit_code = event.observation.exit_code
                status = "‚úì" if exit_code == 0 else "‚úó"
                logger.info(f"   {status} Exit code: {exit_code}")

        # Log errors
        if hasattr(event, "error") and event.error:
            logger.warning(f"‚ö†Ô∏è  Error: {event.error}")

    import time

    start_time = time.time()

    try:
        logger.info("Creating OpenHands conversation...")
        # Use LocalWorkspace for better integration with OpenHands SDK
        workspace_obj = LocalWorkspace(working_dir=str(workspace))

        # Handle unlimited iterations (-1 -> very large number)
        iteration_limit = 1_000_000 if max_iterations == -1 else max_iterations

        # Register event callback for real-time monitoring if verbose
        # Use DelegationVisualizer to enable logging of worker agent actions
        conversation = Conversation(
            agent=agent,
            workspace=workspace_obj,
            callbacks=[on_event] if verbose else None,
            max_iteration_per_run=iteration_limit,
            visualizer=DelegationVisualizer(name="orchestrator"),
        )

        logger.info("Sending prompt to agent...")
        conversation.send_message(prompt)

        logger.info("Running agent review (this may take several minutes)...")

        conversation.run()

        logger.info("Extracting review from agent response...")
        review_content = get_agent_final_response(conversation.state.events)

        if not review_content:
            raise RuntimeError("Agent did not produce any review content")

        # Calculate review time
        review_time_seconds = time.time() - start_time
        review_time_str = f"{int(review_time_seconds // 60)}m {int(review_time_seconds % 60)}s"

        logger.info(f"Review complete ({len(review_content)} chars)")

        # Always print metrics (not just in verbose mode)
        # Aggregate costs from orchestrator AND all workers
        try:
            costs = aggregate_all_costs(conversation)

            print("\n" + "=" * 60)
            print("üìä Cost Summary:")
            print(f"  ‚Ä¢ Orchestrator:       ${costs['orchestrator_cost']:.4f}")

            if costs["worker_costs"]:
                print(f"  ‚Ä¢ Workers total:      ${costs['total_worker_cost']:.4f}")
                if verbose:
                    for agent_id, agent_data in sorted(costs["worker_costs"].items()):
                        print(f"      - {agent_id}: ${agent_data['cost']:.4f}")

            print(f"\nüí∞ TOTAL COST:         ${costs['total_cost']:.4f}")
            print(f"üìù Total tokens:       {costs['total_tokens']:,}")
            print(f"‚è±Ô∏è  Review Time:        {review_time_str}")
            print("=" * 60 + "\n")

        except Exception as e:
            logger.warning(f"Failed to get metrics: {e}")

        return review_content

    except Exception as e:
        logger.error(f"Review failed: {e}")
        raise RuntimeError(f"Review failed: {e}") from e

    finally:
        # Reset terminal by draining leftover control-sequence replies
        _terminal_safety.restore_terminal_state()

        # Clean up workspace
        if workspace and cleanup:
            logger.info("Cleaning up workspace...")
            cleanup_workspace(workspace)
