"""Core agent for PR review using OpenHands SDK."""

import logging
import os
import subprocess
from pathlib import Path
from typing import Any, Literal
from urllib.parse import urlparse

from dotenv import load_dotenv
from openhands.sdk import Conversation
from openhands.sdk.conversation import get_agent_final_response
from openhands.sdk.workspace import LocalWorkspace

from .llm import create_hodor_agent, get_api_key
from .prompts.pr_review_prompt import build_pr_review_prompt
from .skills import discover_skills
from .workspace import cleanup_workspace, setup_workspace

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

Platform = Literal["github", "gitlab"]


def detect_platform(pr_url: str) -> Platform:
    """Detect the platform (GitHub or GitLab) from the PR URL."""
    parsed = urlparse(pr_url)
    hostname = parsed.hostname or ""

    # Check for GitLab-specific patterns first (works for both gitlab.com and self-hosted)
    if "/-/merge_requests/" in pr_url or "gitlab" in hostname:
        return "gitlab"
    # Check for GitHub-specific patterns
    elif "/pull/" in pr_url or "github" in hostname:
        return "github"
    else:
        logger.debug(f"Unknown platform for URL {pr_url}, defaulting to GitHub")
        return "github"


def parse_pr_url(pr_url: str) -> tuple[str, str, int, str]:
    """
    Parse PR/MR URL to extract owner, repo, PR/MR number, and host.

    Examples:
        GitHub: https://github.com/owner/repo/pull/123 -> ('owner', 'repo', 123, 'github.com')
        GitLab: https://gitlab.com/owner/repo/-/merge_requests/123 -> ('owner', 'repo', 123, 'gitlab.com')
        Self-hosted: https://gitlab.example.com/group/repo/-/merge_requests/118 -> ('group', 'repo', 118, 'gitlab.example.com')
    """
    parsed = urlparse(pr_url)
    path_parts = [p for p in parsed.path.split("/") if p]
    host = parsed.netloc

    # GitHub format: /owner/repo/pull/123
    if len(path_parts) >= 4 and path_parts[2] == "pull":
        owner = path_parts[0]
        repo = path_parts[1]
        pr_number = int(path_parts[3])
        return owner, repo, pr_number, host

    # GitLab format: /group/subgroup/repo/-/merge_requests/123
    elif "merge_requests" in path_parts:
        mr_index = path_parts.index("merge_requests")
        if mr_index < 2 or mr_index + 1 >= len(path_parts):
            raise ValueError(f"Invalid GitLab MR URL format: {pr_url}. Expected .../-/merge_requests/<number>")
        if path_parts[mr_index - 1] != "-":
            raise ValueError(f"Invalid GitLab MR URL format: {pr_url}. Missing '/-/' segment before merge_requests.")

        repo = path_parts[mr_index - 2]
        owner_parts = path_parts[: mr_index - 2]
        owner = "/".join(owner_parts) if owner_parts else path_parts[0]
        pr_number = int(path_parts[mr_index + 1])
        return owner, repo, pr_number, host

    else:
        raise ValueError(
            f"Invalid PR/MR URL format: {pr_url}. Expected GitHub pull request or GitLab merge request URL."
        )


def post_review_comment(
    pr_url: str,
    review_text: str,
    model: str | None = None,
) -> dict[str, Any]:
    """
    Post a review comment on a GitHub PR or GitLab MR using CLI tools.

    Args:
        pr_url: URL of the pull request or merge request
        review_text: The review text to post as a comment
        model: LLM model used for the review (optional, for transparency)

    Returns:
        Dictionary with comment posting result
    """
    platform = detect_platform(pr_url)
    logger.info(f"Posting comment to {platform} PR/MR: {pr_url}")

    try:
        owner, repo, pr_number, host = parse_pr_url(pr_url)
    except ValueError as e:
        return {"success": False, "error": str(e)}

    # Append model information to review text for transparency
    if model:
        review_text_with_footer = f"{review_text}\n\n---\n\n*Review generated by Hodor using `{model}`*"
    else:
        review_text_with_footer = review_text

    try:
        if platform == "github":
            # Use gh CLI to post comment
            subprocess.run(
                [
                    "gh",
                    "pr",
                    "review",
                    str(pr_number),
                    "--repo",
                    f"{owner}/{repo}",
                    "--comment",
                    "--body",
                    review_text_with_footer,
                ],
                check=True,
                capture_output=True,
                text=True,
            )
            logger.info(f"Successfully posted review to GitHub PR #{pr_number}")
            return {"success": True, "platform": "github", "pr_number": pr_number}

        elif platform == "gitlab":
            # Use glab CLI to post comment with -R flag (works from any directory)
            # Note: glab needs to be authenticated for the right GitLab instance
            subprocess.run(
                [
                    "glab",
                    "mr",
                    "note",
                    str(pr_number),
                    "-R",
                    f"{owner}/{repo}",  # Specify repo explicitly - works without being in git dir
                    "--message",
                    review_text_with_footer,
                ],
                check=True,
                capture_output=True,
                text=True,
                env={**os.environ},  # Pass GITLAB_HOST if set
            )
            logger.info(f"Successfully posted review to GitLab MR !{pr_number} on {owner}/{repo}")
            return {"success": True, "platform": "gitlab", "mr_number": pr_number}

        else:
            return {"success": False, "error": f"Unsupported platform: {platform}"}

    except subprocess.CalledProcessError as e:
        logger.error(f"Failed to post comment: {e}")
        logger.error(f"Command output: {e.stderr if hasattr(e, 'stderr') else 'N/A'}")
        return {"success": False, "error": str(e)}
    except Exception as e:
        logger.error(f"Error posting comment: {str(e)}")
        return {"success": False, "error": str(e)}


def review_pr(
    pr_url: str,
    model: str = "anthropic/claude-sonnet-4-5-20250929",
    temperature: float | None = None,
    reasoning_effort: str | None = None,
    custom_prompt: str | None = None,
    prompt_file: Path | None = None,
    user_llm_params: dict[str, Any] | None = None,
    verbose: bool = False,
    cleanup: bool = True,
    workspace_dir: Path | None = None,
) -> str:
    """
    Review a pull request using OpenHands agent with bash tools.

    Args:
        pr_url: URL of the pull request or merge request
        model: LLM model name (default: Claude Sonnet 4.5)
        temperature: Sampling temperature (if None, auto-selected)
        reasoning_effort: For reasoning models: "low", "medium", or "high"
        custom_prompt: Optional custom prompt text (inline)
        prompt_file: Optional path to custom prompt file
        user_llm_params: Additional LLM parameters
        verbose: Enable verbose logging
        cleanup: Clean up workspace after review (default: True)
        workspace_dir: Directory to use for workspace (if None, creates temp dir). Reuses if same repo.

    Returns:
        Review text as markdown string

    Raises:
        ValueError: If URL is invalid
        RuntimeError: If review fails
    """
    logger.info(f"Starting PR review for: {pr_url}")

    # Parse PR URL
    try:
        owner, repo, pr_number, host = parse_pr_url(pr_url)
        platform = detect_platform(pr_url)
    except ValueError as e:
        logger.error(f"Invalid PR URL: {e}")
        raise

    logger.info(f"Platform: {platform}, Repo: {owner}/{repo}, PR: {pr_number}, Host: {host}")

    # Setup workspace (clone repo and checkout PR branch)
    workspace = None
    target_branch = "main"  # Default fallback
    try:
        workspace, target_branch = setup_workspace(
            platform=platform,
            owner=owner,
            repo=repo,
            pr_number=str(pr_number),
            host=host,
            working_dir=workspace_dir,
            reuse=workspace_dir is not None,  # Only reuse if user specified a workspace dir
        )
        logger.info(f"Workspace ready: {workspace} (target branch: {target_branch})")
    except Exception as e:
        logger.error(f"Failed to setup workspace: {e}")
        raise RuntimeError(f"Failed to setup workspace: {e}") from e

    # Discover repository skills (from .cursorrules, agents.md, .hodor/skills/)
    skills = []
    try:
        skills = discover_skills(workspace)
        if skills:
            logger.info(f"Discovered {len(skills)} repository skill(s)")
        else:
            logger.debug("No repository skills found")
    except Exception as e:
        logger.warning(f"Failed to discover skills (continuing without skills): {e}")

    # Create OpenHands agent with repository skills
    try:
        agent = create_hodor_agent(
            model=model,
            temperature=temperature,
            reasoning_effort=reasoning_effort,
            verbose=verbose,
            llm_overrides=user_llm_params,
            skills=skills,
        )
    except Exception as e:
        logger.error(f"Failed to create OpenHands agent: {e}")
        if workspace and cleanup:
            cleanup_workspace(workspace)
        raise RuntimeError(f"Failed to create agent: {e}") from e

    # Build prompt
    try:
        prompt = build_pr_review_prompt(
            pr_url=pr_url,
            owner=owner,
            repo=repo,
            pr_number=str(pr_number),
            platform=platform,
            target_branch=target_branch,
            custom_instructions=custom_prompt,
            custom_prompt_file=prompt_file,
        )
    except Exception as e:
        logger.error(f"Failed to build prompt: {e}")
        if workspace and cleanup:
            cleanup_workspace(workspace)
        raise RuntimeError(f"Failed to build prompt: {e}") from e

    #  Event callback for monitoring agent progress
    def on_event(event: Any) -> None:
        """Callback for streaming agent events in verbose mode."""
        if not verbose:
            return

        event_type = type(event).__name__

        # Log LLM API calls (for detailed token/cost tracking)
        from openhands.events.event import LLMConvertibleEvent

        if isinstance(event, LLMConvertibleEvent):
            # This captures raw LLM messages for detailed analysis
            # Useful for debugging prompt engineering or cost optimization
            logger.debug(f"ðŸ¤– LLM Event: {event_type}")

        # Log agent actions
        if hasattr(event, "action") and event.action:
            action_type = type(event.action).__name__
            if action_type == "ExecuteBashAction":
                logger.info(f"ðŸ”§ Executing: {event.action.command[:100]}")
            elif action_type == "FileEditAction":
                logger.info(f"âœï¸  Editing file: {getattr(event.action, 'file_path', 'unknown')}")
            elif action_type == "MessageAction":
                logger.info(f"ðŸ’¬ Agent thinking...")

        # Log observations (results)
        if hasattr(event, "observation") and event.observation:
            obs_type = type(event.observation).__name__
            if obs_type == "ExecuteBashObservation" and hasattr(event.observation, "exit_code"):
                exit_code = event.observation.exit_code
                status = "âœ“" if exit_code == 0 else "âœ—"
                logger.info(f"   {status} Exit code: {exit_code}")

        # Log errors
        if hasattr(event, "error") and event.error:
            logger.warning(f"âš ï¸  Error: {event.error}")

    import time

    start_time = time.time()

    try:
        logger.info("Creating OpenHands conversation...")
        # Use LocalWorkspace for better integration with OpenHands SDK
        workspace_obj = LocalWorkspace(working_dir=str(workspace))
        conversation = Conversation(agent=agent, workspace=workspace_obj)

        logger.info("Sending prompt to agent...")
        conversation.send_message(prompt)

        logger.info("Running agent review (this may take several minutes)...")

        # Run with event streaming if verbose
        if verbose:
            # Register event callback for real-time monitoring
            conversation._state.on_event = on_event

        conversation.run()

        logger.info("Extracting review from agent response...")
        review_content = get_agent_final_response(conversation.state.events)

        if not review_content:
            raise RuntimeError("Agent did not produce any review content")

        # Calculate review time
        review_time_seconds = time.time() - start_time
        review_time_str = f"{int(review_time_seconds // 60)}m {int(review_time_seconds % 60)}s"

        logger.info(f"Review complete ({len(review_content)} chars)")

        # Always print metrics (not just in verbose mode)
        # Access metrics via conversation.conversation_stats (SDK API)
        if hasattr(conversation, "conversation_stats"):
            try:
                combined = conversation.conversation_stats.get_combined_metrics()

                if combined and combined.accumulated_token_usage:
                    # Token usage breakdown from Metrics object
                    usage = combined.accumulated_token_usage
                    prompt_tokens = usage.prompt_tokens or 0
                    completion_tokens = usage.completion_tokens or 0
                    cache_read_tokens = usage.cache_read_tokens or 0
                    cache_write_tokens = usage.cache_write_tokens or 0
                    reasoning_tokens = usage.reasoning_tokens or 0
                    total_tokens = prompt_tokens + completion_tokens + cache_read_tokens + reasoning_tokens

                    # Cost estimate
                    cost = combined.accumulated_cost or 0

                    # Calculate cache hit rate
                    cache_hit_rate = 0
                    if cache_read_tokens > 0 and (prompt_tokens + cache_read_tokens) > 0:
                        cache_hit_rate = (cache_read_tokens / (prompt_tokens + cache_read_tokens)) * 100

                    # Print metrics (always, not just verbose)
                    print("\n" + "=" * 60)
                    print("ðŸ“Š Token Usage Metrics:")
                    print(f"  â€¢ Input tokens:       {prompt_tokens:,}")
                    print(f"  â€¢ Output tokens:      {completion_tokens:,}")
                    if cache_read_tokens > 0:
                        print(f"  â€¢ Cache hits:         {cache_read_tokens:,} ({cache_hit_rate:.1f}%)")
                    if reasoning_tokens > 0:
                        print(f"  â€¢ Reasoning tokens:   {reasoning_tokens:,}")
                    print(f"  â€¢ Total tokens:       {total_tokens:,}")
                    print(f"\nðŸ’° Cost Estimate:      ${cost:.4f}")
                    print(f"â±ï¸  Review Time:        {review_time_str}")
                    print("=" * 60 + "\n")

                    # Verbose mode: additional details
                    if verbose:
                        if cache_write_tokens > 0:
                            logger.info(f"  â€¢ Cache writes:       {cache_write_tokens:,}")
                        if combined.response_latencies:
                            avg_latency = sum(combined.response_latencies) / len(combined.response_latencies)
                            logger.info(f"  â€¢ Avg API latency:    {avg_latency:.2f}s")
            except Exception as e:
                logger.warning(f"Failed to get metrics: {e}")

        return review_content

    except Exception as e:
        logger.error(f"Review failed: {e}")
        raise RuntimeError(f"Review failed: {e}") from e

    finally:
        # Reset terminal to prevent corruption from PTY
        # The subprocess terminal can leave escape sequences that corrupt the parent shell
        try:
            import sys
            import subprocess as sp

            # Reset terminal attributes if we're in a TTY (without clearing screen)
            if sys.stdin.isatty():
                # Use stty sane to reset terminal to sensible defaults
                sp.run(
                    ["stty", "sane"],
                    stdin=sys.stdin,
                    stdout=sp.DEVNULL,
                    stderr=sp.DEVNULL,
                    check=False,
                )
        except Exception:
            pass  # Silently ignore if terminal reset fails

        # Clean up workspace
        if workspace and cleanup:
            logger.info("Cleaning up workspace...")
            cleanup_workspace(workspace)
